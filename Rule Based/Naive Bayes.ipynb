{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60db95b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>146</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>147</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>148</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>149</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
       "0      1            5.1           3.5            1.4           0.2   \n",
       "1      2            4.9           3.0            1.4           0.2   \n",
       "2      3            4.7           3.2            1.3           0.2   \n",
       "3      4            4.6           3.1            1.5           0.2   \n",
       "4      5            5.0           3.6            1.4           0.2   \n",
       "..   ...            ...           ...            ...           ...   \n",
       "145  146            6.7           3.0            5.2           2.3   \n",
       "146  147            6.3           2.5            5.0           1.9   \n",
       "147  148            6.5           3.0            5.2           2.0   \n",
       "148  149            6.2           3.4            5.4           2.3   \n",
       "149  150            5.9           3.0            5.1           1.8   \n",
       "\n",
       "            Species  \n",
       "0       Iris-setosa  \n",
       "1       Iris-setosa  \n",
       "2       Iris-setosa  \n",
       "3       Iris-setosa  \n",
       "4       Iris-setosa  \n",
       "..              ...  \n",
       "145  Iris-virginica  \n",
       "146  Iris-virginica  \n",
       "147  Iris-virginica  \n",
       "148  Iris-virginica  \n",
       "149  Iris-virginica  \n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the Iris dataset using Pandas\n",
    "data = pd.read_csv('Iris.csv')\n",
    "data.values.tolist()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956b2354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e91df80",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2776\\1852653466.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Split the dataset into a training set and a testing set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msplit_ratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "# Split the dataset into a training set and a testing set\n",
    "split_ratio = 0.8\n",
    "train_set, test_set = train_test_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4358c595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(numbers):\n",
    "    print(numbers)\n",
    "    return sum(numbers) / float(len(numbers))\n",
    "\n",
    "# Calculate the standard deviation of a list of numbers\n",
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum([(x - avg) ** 2 for x in numbers]) / float(len(numbers) - 1)\n",
    "    return math.sqrt(variance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "377f8c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I',)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14424\\548555327.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;31m# Train and test the Naive Bayes classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_algorithm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;31m# Calculate the accuracy of the classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14424\\548555327.py\u001b[0m in \u001b[0;36mevaluate_algorithm\u001b[1;34m(train, test)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mevaluate_algorithm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m     \u001b[0msummaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msummarize_by_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14424\\548555327.py\u001b[0m in \u001b[0;36msummarize_by_class\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0msummaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mclass_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstances\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mseparated\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0msummaries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclass_value\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msummarize_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msummaries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14424\\548555327.py\u001b[0m in \u001b[0;36msummarize_dataset\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# Calculate the mean and standard deviation for each feature in the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msummarize_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0msummaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdev\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0msummaries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Exclude the class column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msummaries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14424\\548555327.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# Calculate the mean and standard deviation for each feature in the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msummarize_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0msummaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdev\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0msummaries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Exclude the class column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msummaries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14424\\548555327.py\u001b[0m in \u001b[0;36mmean\u001b[1;34m(numbers)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Calculate the standard deviation of a list of numbers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "# Separate the dataset by class values\n",
    "def separate_by_class(dataset):\n",
    "    separated = {}\n",
    "    for row in dataset:\n",
    "        class_value = row[-1]\n",
    "        if class_value not in separated:\n",
    "            separated[class_value] = []\n",
    "        separated[class_value].append(row)\n",
    "    return separated\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the mean and standard deviation for each feature in the dataset\n",
    "def summarize_dataset(dataset):\n",
    "    summaries = [(mean(column), stdev(column)) for column in zip(*dataset)]\n",
    "    del summaries[-1]  # Exclude the class column\n",
    "    return summaries\n",
    "\n",
    "# Split the dataset by class and then calculate statistics for each attribute\n",
    "def summarize_by_class(dataset):\n",
    "    separated = separate_by_class(dataset)\n",
    "    summaries = {}\n",
    "    for class_value, instances in separated.items():\n",
    "        summaries[class_value] = summarize_dataset(instances)\n",
    "    return summaries\n",
    "\n",
    "# Calculate the Gaussian probability density function\n",
    "def calculate_probability(x, mean, stdev):\n",
    "    exponent = math.exp(-((x - mean) ** 2 / (2 * stdev ** 2)))\n",
    "    return (1 / (math.sqrt(2 * math.pi) * stdev)) * exponent\n",
    "\n",
    "# Calculate the class probabilities for a given input\n",
    "def calculate_class_probabilities(summaries, input_vector):\n",
    "    probabilities = {}\n",
    "    for class_value, class_summaries in summaries.items():\n",
    "        probabilities[class_value] = 1\n",
    "        for i in range(len(class_summaries)):\n",
    "            mean, stdev = class_summaries[i]\n",
    "            x = input_vector[i]\n",
    "            probabilities[class_value] *= calculate_probability(x, mean, stdev)\n",
    "    return probabilities\n",
    "\n",
    "# Make a prediction for a given input\n",
    "def predict(summaries, input_vector):\n",
    "    probabilities = calculate_class_probabilities(summaries, input_vector)\n",
    "    best_label, best_prob = None, -1\n",
    "    for class_value, probability in probabilities.items():\n",
    "        if best_label is None or probability > best_prob:\n",
    "            best_prob = probability\n",
    "            best_label = class_value\n",
    "    return best_label\n",
    "\n",
    "def evaluate_algorithm(train, test):\n",
    "    summaries = summarize_by_class(train)\n",
    "    predictions = []\n",
    "    for row in test:\n",
    "        prediction = predict(summaries, row)\n",
    "        predictions.append(prediction)\n",
    "    return predictions\n",
    "\n",
    "# Train and test the Naive Bayes classifier\n",
    "predictions = evaluate_algorithm(train_set, test_set)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "correct = 0\n",
    "for i in range(len(test_set)):\n",
    "    if test_set[i][-1] == predictions[i]:\n",
    "        correct += 1\n",
    "accuracy = correct / float(len(test_set)) * 100.0\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dae660e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "192bc69a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14424\\2017092739.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;31m# Train and test the Naive Bayes classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_algorithm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;31m# Calculate the accuracy of the classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14424\\2017092739.py\u001b[0m in \u001b[0;36mevaluate_algorithm\u001b[1;34m(train, test)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;31m# Evaluate the model on a testing dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mevaluate_algorithm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[0msummaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msummarize_by_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14424\\2017092739.py\u001b[0m in \u001b[0;36msummarize_by_class\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0msummaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mclass_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstances\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mseparated\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0msummaries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclass_value\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msummarize_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msummaries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14424\\2017092739.py\u001b[0m in \u001b[0;36msummarize_dataset\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m# Calculate the mean and standard deviation for each feature in the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msummarize_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[0msummaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdev\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0msummaries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Exclude the class column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msummaries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14424\\2017092739.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m# Calculate the mean and standard deviation for each feature in the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msummarize_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[0msummaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdev\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0msummaries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Exclude the class column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msummaries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14424\\2017092739.py\u001b[0m in \u001b[0;36mmean\u001b[1;34m(numbers)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert the Pandas DataFrame to a list of lists for compatibility\n",
    "data = data.values.tolist()\n",
    "data\n",
    "\n",
    "\n",
    "# Load data from the dataset\n",
    "def load_data(data):\n",
    "    dataset = []\n",
    "    for row in data:\n",
    "        dataset.append(row)\n",
    "    return dataset\n",
    "\n",
    "# Convert string values to float\n",
    "def str_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column])\n",
    "\n",
    "# Split the dataset into a training set and a testing set\n",
    "def train_test_split(dataset, split_ratio):\n",
    "    random.shuffle(dataset)\n",
    "    split_point = int(len(dataset) * split_ratio)\n",
    "    return dataset[:split_point], dataset[split_point:]\n",
    "\n",
    "# Separate the dataset by class values\n",
    "def separate_by_class(dataset):\n",
    "    separated = {}\n",
    "    for row in dataset:\n",
    "        class_value = row[-1]\n",
    "        if class_value not in separated:\n",
    "            separated[class_value] = []\n",
    "        separated[class_value].append(row)\n",
    "    return separated\n",
    "\n",
    "def mean(numbers):\n",
    "    return sum(numbers) / float(len(numbers))\n",
    "\n",
    "                            \n",
    "# Calculate the standard deviation of a list of numbers\n",
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum([(x - avg) ** 2 for x in numbers]) / float(len(numbers) - 1)\n",
    "    return math.sqrt(variance)\n",
    "\n",
    "# Calculate the mean and standard deviation for each feature in the dataset\n",
    "def summarize_dataset(dataset):\n",
    "    summaries = [(mean(column), stdev(column)) for column in zip(*dataset)]\n",
    "    del summaries[-1]  # Exclude the class column\n",
    "    return summaries\n",
    "\n",
    "# Split the dataset by class and then calculate statistics for each attribute\n",
    "def summarize_by_class(dataset):\n",
    "    separated = separate_by_class(dataset)\n",
    "    summaries = {}\n",
    "    for class_value, instances in separated.items():\n",
    "        summaries[class_value] = summarize_dataset(instances)\n",
    "    return summaries\n",
    "\n",
    "# Calculate the Gaussian probability density function\n",
    "def calculate_probability(x, mean, stdev):\n",
    "    exponent = math.exp(-((x - mean) ** 2 / (2 * stdev ** 2)))\n",
    "    return (1 / (math.sqrt(2 * math.pi) * stdev)) * exponent\n",
    "\n",
    "# Calculate the class probabilities for a given input\n",
    "def calculate_class_probabilities(summaries, input_vector):\n",
    "    probabilities = {}\n",
    "    for class_value, class_summaries in summaries.items():\n",
    "        probabilities[class_value] = 1\n",
    "        for i in range(len(class_summaries)):\n",
    "            mean, stdev = class_summaries[i]\n",
    "            x = input_vector[i]\n",
    "            probabilities[class_value] *= calculate_probability(x, mean, stdev)\n",
    "    return probabilities\n",
    "\n",
    "# Make a prediction for a given input\n",
    "def predict(summaries, input_vector):\n",
    "    probabilities = calculate_class_probabilities(summaries, input_vector)\n",
    "    best_label, best_prob = None, -1\n",
    "    for class_value, probability in probabilities.items():\n",
    "        if best_label is None or probability > best_prob:\n",
    "            best_prob = probability\n",
    "            best_label = class_value\n",
    "    return best_label\n",
    "\n",
    "# Evaluate the model on a testing dataset\n",
    "def evaluate_algorithm(train, test):\n",
    "    summaries = summarize_by_class(train)\n",
    "    predictions = []\n",
    "    for row in test:\n",
    "        prediction = predict(summaries, row)\n",
    "        predictions.append(prediction)\n",
    "    return predictions\n",
    "\n",
    "# Train and test the Naive Bayes classifier\n",
    "predictions = evaluate_algorithm(train_set, test_set)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "correct = 0\n",
    "for i in range(len(test_set)):\n",
    "    if test_set[i][-1] == predictions[i]:\n",
    "        correct += 1\n",
    "accuracy = correct / float(len(test_set)) * 100.0\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b589b6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8745b70e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be15cb73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbecc6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae383f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77622769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a78da43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "175c0614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8313713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data = []\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "    return data\n",
    "\n",
    "def split_data(data, split_ratio):\n",
    "    split_index = int(len(data) * split_ratio)\n",
    "    training_data = data[:split_index]\n",
    "    testing_data = data[split_index:]\n",
    "    return training_data, testing_data\n",
    "\n",
    "def calculate_prior_probabilities(training_data, class_column):\n",
    "    class_counts = defaultdict(int)\n",
    "    total_count = len(training_data)\n",
    "\n",
    "    for row in training_data:\n",
    "        class_label = row[class_column]\n",
    "        class_counts[class_label] += 1\n",
    "\n",
    "    prior_probabilities = {}\n",
    "    for class_label, count in class_counts.items():\n",
    "        prior_probabilities[class_label] = count / total_count\n",
    "\n",
    "    return prior_probabilities\n",
    "\n",
    "def calculate_likelihoods(training_data, class_column):\n",
    "    likelihoods = {}\n",
    "    num_features = len(training_data[0]) - 1  # Number of columns excluding the class column\n",
    "\n",
    "    for row in training_data:\n",
    "        class_label = row[class_column]\n",
    "        if class_label not in likelihoods:\n",
    "            likelihoods[class_label] = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "        for i in range(num_features):\n",
    "            feature_value = row[i]\n",
    "            likelihoods[class_label][i][feature_value] += 1\n",
    "\n",
    "    return likelihoods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cd4db1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(test_instance, prior_probabilities, likelihoods, num_features):\n",
    "    best_class = None\n",
    "    max_posterior = -1\n",
    "\n",
    "    for class_label in prior_probabilities:\n",
    "        posterior = math.log(prior_probabilities[class_label])\n",
    "\n",
    "        for i in range(num_features):\n",
    "            feature_value = test_instance[i]\n",
    "            if feature_value in likelihoods[class_label][i]:\n",
    "                likelihood = (likelihoods[class_label][i][feature_value] + 1) / (\n",
    "                    sum(likelihoods[class_label][i].values()) + len(likelihoods[class_label][i])\n",
    "                )\n",
    "            else:\n",
    "                likelihood = 1 / (sum(likelihoods[class_label][i].values()) + len(likelihoods[class_label][i]))\n",
    "\n",
    "            posterior += math.log(likelihood)\n",
    "\n",
    "        if posterior > max_posterior:\n",
    "            max_posterior = posterior\n",
    "            best_class = class_label\n",
    "\n",
    "    return best_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbbeaaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Feature1 Feature2 Class\n",
      "0      Sunny      Hot   Yes\n",
      "1      Sunny      Hot   Yes\n",
      "2   Overcast      Hot   Yes\n",
      "3      Rainy     Mild   Yes\n",
      "4      Rainy     Cool   Yes\n",
      "5      Rainy     Cool    No\n",
      "6   Overcast     Cool    No\n",
      "7      Sunny     Mild   Yes\n",
      "8      Sunny     Cool   Yes\n",
      "9      Rainy     Mild    No\n",
      "10     Sunny     Mild    No\n",
      "11  Overcast     Mild   Yes\n",
      "12  Overcast      Hot    No\n",
      "13     Rainy     Mild   Yes\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3628\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3629\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2776\\1916334023.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtesting_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_ratio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprior_probabilities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_prior_probabilities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_column\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mlikelihoods\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_likelihoods\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_column\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mnum_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m  \u001b[1;31m# Number of columns excluding the class column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2776\\3331543174.py\u001b[0m in \u001b[0;36mcalculate_likelihoods\u001b[1;34m(training_data, class_column)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcalculate_likelihoods\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_column\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mlikelihoods\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mnum_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m  \u001b[1;31m# Number of columns excluding the class column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3504\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3505\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3506\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3507\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3629\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3631\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3632\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3633\u001b[0m                 \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "filename = 'synthetic_dataset.csv'\n",
    "# data = load_data(filename)\n",
    "data = pd.read_csv(filename)\n",
    "print(data)\n",
    "split_ratio = 0.8  # 80% for training, 20% for testing\n",
    "class_column = -1  # Assuming the last column contains class labels\n",
    "\n",
    "training_data, testing_data = split_data(data, split_ratio)\n",
    "prior_probabilities = calculate_prior_probabilities(training_data, class_column)\n",
    "likelihoods = calculate_likelihoods(training_data, class_column)\n",
    "num_features = len(training_data[0]) - 1  # Number of columns excluding the class column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8364cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = 0\n",
    "total_predictions = len(testing_data)\n",
    "\n",
    "for test_instance in testing_data:\n",
    "    predicted_class = classify(test_instance, prior_probabilities, likelihoods, num_features)\n",
    "    if predicted_class == test_instance[class_column]:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = (correct_predictions / total_predictions) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20e2abd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples are:  777\n",
      "Out of these, training examples are:  543\n",
      "Test examples are:  234\n",
      "351\n",
      "351\n",
      "351\n",
      "351\n",
      "351\n",
      "351\n",
      "351\n",
      "351\n",
      "351\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "1\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2776\\1925256521.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;31m# prepare model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMeanAndStdDevForClass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;31m# test model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2776\\1925256521.py\u001b[0m in \u001b[0;36mMeanAndStdDevForClass\u001b[1;34m(mydata)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mdict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroupUnderClass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmydata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mclassValue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstances\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m                 \u001b[0minfo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclassValue\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMeanAndStdDev\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2776\\1925256521.py\u001b[0m in \u001b[0;36mMeanAndStdDev\u001b[1;34m(mydata)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mMeanAndStdDev\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmydata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattribute\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd_dev\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattribute\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mattribute\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmydata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[1;31m# eg: list = [ [a, b, c], [m, n, o], [x, y, z]]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;31m# here mean of 1st attribute =(a + m+x), mean of 2nd attribute = (b + n+y)/3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2776\\1925256521.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mMeanAndStdDev\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmydata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattribute\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd_dev\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattribute\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mattribute\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmydata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[1;31m# eg: list = [ [a, b, c], [m, n, o], [x, y, z]]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;31m# here mean of 1st attribute =(a + m+x), mean of 2nd attribute = (b + n+y)/3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2776\\1925256521.py\u001b[0m in \u001b[0;36mstd_dev\u001b[1;34m(numbers)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mavg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0mvariance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mavg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "# Importing library\n",
    "import math\n",
    "import random\n",
    "import csv\n",
    "\n",
    "\n",
    "# the categorical class names are changed to numberic data\n",
    "# eg: yes and no encoded to 1 and 0\n",
    "def encode_class(mydata):\n",
    "\tclasses = []\n",
    "\tfor i in range(len(mydata)):\n",
    "\t\tif mydata[i][-1] not in classes:\n",
    "\t\t\tclasses.append(mydata[i][-1])\n",
    "\tfor i in range(len(classes)):\n",
    "\t\tfor j in range(len(mydata)):\n",
    "\t\t\tif mydata[j][-1] == classes[i]:\n",
    "\t\t\t\tmydata[j][-1] = i\n",
    "\treturn mydata\t\t \n",
    "\t\t\t\n",
    "\n",
    "# Splitting the data\n",
    "def splitting(mydata, ratio):\n",
    "\ttrain_num = int(len(mydata) * ratio)\n",
    "\ttrain = []\n",
    "\t# initially testset will have all the dataset \n",
    "\ttest = list(mydata)\n",
    "\twhile len(train) < train_num:\n",
    "\t\t# index generated randomly from range 0 \n",
    "\t\t# to length of testset\n",
    "\t\tindex = random.randrange(len(test))\n",
    "\t\t# from testset, pop data rows and put it in train\n",
    "\t\ttrain.append(test.pop(index))\n",
    "\treturn train, test\n",
    "\n",
    "\n",
    "# Group the data rows under each class yes or \n",
    "# no in dictionary eg: dict[yes] and dict[no] \n",
    "def groupUnderClass(mydata):\n",
    "\tdict = {}\n",
    "\tfor i in range(len(mydata)):\n",
    "\t\tif (mydata[i][-1] not in dict):\n",
    "\t\t\tdict[mydata[i][-1]] = []\n",
    "\t\tdict[mydata[i][-1]].append(mydata[i])\n",
    "\treturn dict\n",
    "\n",
    "\n",
    "# Calculating Mean\n",
    "def mean(numbers):\n",
    "\treturn sum(numbers) / float(len(numbers))\n",
    "\n",
    "# Calculating Standard Deviation\n",
    "def std_dev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    print(len(numbers))\n",
    "    variance = sum([pow(x - avg, 2) for x in numbers]) / float(len(numbers) - 1)\n",
    "    return math.sqrt(variance)\n",
    "\n",
    "def MeanAndStdDev(mydata):\n",
    "\tinfo = [(mean(attribute), std_dev(attribute)) for attribute in zip(*mydata)]\n",
    "\t# eg: list = [ [a, b, c], [m, n, o], [x, y, z]]\n",
    "\t# here mean of 1st attribute =(a + m+x), mean of 2nd attribute = (b + n+y)/3\n",
    "\t# delete summaries of last class\n",
    "\tdel info[-1]\n",
    "\treturn info\n",
    "\n",
    "# find Mean and Standard Deviation under each class\n",
    "def MeanAndStdDevForClass(mydata):\n",
    "\tinfo = {}\n",
    "\tdict = groupUnderClass(mydata)\n",
    "\tfor classValue, instances in dict.items():\n",
    "\t\tinfo[classValue] = MeanAndStdDev(instances)\n",
    "\treturn info\n",
    "\n",
    "\n",
    "# Calculate Gaussian Probability Density Function\n",
    "def calculateGaussianProbability(x, mean, stdev):\n",
    "\texpo = math.exp(-(math.pow(x - mean, 2) / (2 * math.pow(stdev, 2))))\n",
    "\treturn (1 / (math.sqrt(2 * math.pi) * stdev)) * expo\n",
    "\n",
    "\n",
    "# Calculate Class Probabilities\n",
    "def calculateClassProbabilities(info, test):\n",
    "\tprobabilities = {}\n",
    "\tfor classValue, classSummaries in info.items():\n",
    "\t\tprobabilities[classValue] = 1\n",
    "\t\tfor i in range(len(classSummaries)):\n",
    "\t\t\tmean, std_dev = classSummaries[i]\n",
    "\t\t\tx = test[i]\n",
    "\t\t\tprobabilities[classValue] *= calculateGaussianProbability(x, mean, std_dev)\n",
    "\treturn probabilities\n",
    "\n",
    "\n",
    "# Make prediction - highest probability is the prediction\n",
    "def predict(info, test):\n",
    "\tprobabilities = calculateClassProbabilities(info, test)\n",
    "\tbestLabel, bestProb = None, -1\n",
    "\tfor classValue, probability in probabilities.items():\n",
    "\t\tif bestLabel is None or probability > bestProb:\n",
    "\t\t\tbestProb = probability\n",
    "\t\t\tbestLabel = classValue\n",
    "\treturn bestLabel\n",
    "\n",
    "\n",
    "# returns predictions for a set of examples\n",
    "def getPredictions(info, test):\n",
    "\tpredictions = []\n",
    "\tfor i in range(len(test)):\n",
    "\t\tresult = predict(info, test[i])\n",
    "\t\tpredictions.append(result)\n",
    "\treturn predictions\n",
    "\n",
    "# Accuracy score\n",
    "def accuracy_rate(test, predictions):\n",
    "\tcorrect = 0\n",
    "\tfor i in range(len(test)):\n",
    "\t\tif test[i][-1] == predictions[i]:\n",
    "\t\t\tcorrect += 1\n",
    "\treturn (correct / float(len(test))) * 100.0\n",
    "\n",
    "\n",
    "# driver code\n",
    "\n",
    "# add the data path in your system\n",
    "filename = r'D:\\pima-indians-diabetes.csv'\n",
    "\n",
    "\n",
    "# load the file and store it in mydata list\n",
    "mydata = csv.reader(open(filename, \"rt\"))\n",
    "mydata = list(mydata)\n",
    "mydata = encode_class(mydata)\n",
    "for i in range(len(mydata)):\n",
    "\tmydata[i] = [float(x) for x in mydata[i]]\n",
    "\n",
    "\t\n",
    "# split ratio = 0.7 \n",
    "# 70% of data is training data and 30% is test data used for testing\n",
    "ratio = 0.7\n",
    "train_data, test_data = splitting(mydata, ratio)\n",
    "print('Total number of examples are: ', len(mydata))\n",
    "print('Out of these, training examples are: ', len(train_data))\n",
    "print(\"Test examples are: \", len(test_data))\n",
    "\n",
    "# prepare model\n",
    "info = MeanAndStdDevForClass(train_data)\n",
    "\n",
    "# test model\n",
    "predictions = getPredictions(info, test_data)\n",
    "accuracy = accuracy_rate(test_data, predictions)\n",
    "print(\"Accuracy of your model is: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2335fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
